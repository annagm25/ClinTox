{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b29fda",
   "metadata": {},
   "source": [
    "# ECFP Feature Engineering for Traditional ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39a61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96c48af6",
   "metadata": {},
   "source": [
    "Our goal in this step is to convert the list of SMILES strings from `clintox.csv` into a numerical format that traditional machine learning models, like  Logistic Regression or Random Forest\n",
    "\n",
    "The most common and effective way to do this is by using molecular fingerprints. We will use Extended-Connectivity Fingerprints (ECFP), which are called Morgan Fingerprints in the RDKit library.\n",
    "\n",
    "What is a Morgan Fingerprint (ECFP)?\n",
    "\n",
    "If we think of a molecule as a graph of atoms (nodes) and bonds (edges).\n",
    "\n",
    "    A fingerprint algorithm \"looks\" at every atom in the molecule.\n",
    "\n",
    "    It identifies all the small sub-structures surrounding that atom up to a certain distance (this distance is the radius).\n",
    "\n",
    "    It hashes each unique sub-structure into an ID.\n",
    "\n",
    "    It creates a long vector (e.g., of 2048 bits) of all zeros.\n",
    "\n",
    "    If a specific sub-structure is present anywhere in the molecule, it \"flips\" the bit at that sub-structure's ID from 0 to 1.\n",
    "\n",
    "The result is a binary vector (a list of 0s and 1s) of a fixed length (e.g., 2048) for every molecule. This vector is our feature set (X).\n",
    "\n",
    "    radius: We will use a radius of 2. This is often called \"ECFP4\" (diameter 4). It's a standard choice that captures enough local information without being too specific.\n",
    "\n",
    "    nBits: We will use nBits=2048. This is the length of our vector. It's large enough to avoid most \"hash collisions\" (where two different sub-structures get the same ID) for a dataset of this size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba036119",
   "metadata": {},
   "source": [
    "### So, let's code it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa15af",
   "metadata": {},
   "source": [
    "#### 1- Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6fd38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdMolDescriptors\n",
    "from rdkit.DataStructs import cDataStructs # For explicit bit vector conversion\n",
    "import warnings\n",
    "\n",
    "# Suppress RDKit warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81a195",
   "metadata": {},
   "source": [
    "#### Load the dataset and set values of the `radius` and the `bits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52c25b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded clintox.csv. Found 1477 compounds.\n"
     ]
    }
   ],
   "source": [
    "# Radius for the Morgan Fingerprint (radius=2 is standard for ECFP4)\n",
    "FP_RADIUS = 2\n",
    "\n",
    "# Number of bits in the fingerprint vector\n",
    "FP_NBITS = 2048\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(\"C:/Users/jmurd/OneDrive/Escritorio/UPV/2025-2026 (NTNU)/Data Science/Proyecto/ClinTox/data/clintox.csv\")\n",
    "    print(f\"Successfully loaded clintox.csv. Found {len(data)} compounds.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: clintox.csv not found. Make sure it's in the same directory.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af5c1c",
   "metadata": {},
   "source": [
    "#### 3- Define our function to transform the smiles strings into Morgan Fingerprint (ECFP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "223a325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ecfp(smiles_string, radius, nbits):\n",
    "        mol = Chem.MolFromSmiles(smiles_string)\n",
    "        if mol is None:\n",
    "            # print(f\"Warning: Could not parse SMILES: {smiles_string}\")\n",
    "            return None\n",
    "        \n",
    "        fp = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, nBits=nbits)\n",
    "        \n",
    "        fp_array = np.zeros((nbits,), dtype=np.int8)\n",
    "        cDataStructs.ConvertToNumpyArray(fp, fp_array)\n",
    "        return fp_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07580a2",
   "metadata": {},
   "source": [
    "#### 4-Process the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "679709f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fingerprint generation complete.\n",
      "Shape of X (features matrix): (1477, 2048)\n",
      "Shape of y (labels vector): (1477,)\n",
      "\n",
      "Successfully saved features (X) and labels (y) to 'clintox_ecfp_features.npz'\n"
     ]
    }
   ],
   "source": [
    "fingerprints_list = []\n",
    "labels_list = []\n",
    "    \n",
    "# Suppress warnings for invalid SMILES during processing loop\n",
    "invalid_smiles_count = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    smiles = row['SMILES']\n",
    "    label = row['CT_TOX']\n",
    "    fp_array = generate_ecfp(smiles, FP_RADIUS, FP_NBITS)\n",
    "        \n",
    "    if fp_array is not None:\n",
    "        fingerprints_list.append(fp_array)\n",
    "        labels_list.append(label)\n",
    "    else:\n",
    "        invalid_smiles_count += 1\n",
    "\n",
    "if invalid_smiles_count > 0:\n",
    "    print(f\"Warning: Skipped {invalid_smiles_count} invalid/unparsable SMILES strings.\")\n",
    "\n",
    "# ---Create Final X and y Matrices ---\n",
    "X = np.array(fingerprints_list)\n",
    "y = np.array(labels_list)\n",
    "    \n",
    "print(\"...Fingerprint generation complete.\")\n",
    "print(f\"Shape of X (features matrix): {X.shape}\")\n",
    "print(f\"Shape of y (labels vector): {y.shape}\")\n",
    "\n",
    "# --- Save the results in .npz format ---\n",
    "output_filename = 'clintox_ecfp_features.npz'\n",
    "np.savez_compressed(output_filename, X=X, y=y)\n",
    "    \n",
    "print(f\"\\nSuccessfully saved features (X) and labels (y) to '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0e281",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9621ee9",
   "metadata": {},
   "source": [
    "### We have our desired X and Y features, so we can proced with the train and test split to train basic machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c74abd",
   "metadata": {},
   "source": [
    "To divide the data we will use the `Scaffold` split\n",
    "- `Why?`  A standard \"random split\" is not good for molecular data. Molecules often come in families that share the same core \"scaffold.\" A random split might put \"Molecule A\" in the training set and its nearly identical \"Cousin B\" in the test set. The model would easily get \"Cousin B\" right, giving you a falsely high score.\n",
    "- A scaffold split analyzes the core structure of every molecule. It guarantees that all molecules sharing the same scaffold end up in the same set (e.g., all in training, or all in testing). This is a much harder, more realistic test of the model's ability to generalize to new, unseen chemical families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8573052e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SMILES from clintox.csv...\n",
      "Data synchronized. 1477 valid molecules ready.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    data_npz = np.load('clintox_ecfp_features.npz')\n",
    "    X = data_npz['X']\n",
    "    y = data_npz['y']\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'clintox_ecfp_features.npz' not found\")\n",
    "    raise\n",
    "\n",
    "# Load the original CSV to get the SMILES\n",
    "print(\"Loading SMILES from clintox.csv...\")\n",
    "data_csv = pd.read_csv(\"C:/Users/jmurd/OneDrive/Escritorio/UPV/2025-2026 (NTNU)/Data Science/Proyecto/ClinTox/data/clintox.csv\") \n",
    "\n",
    "# --- 2. Synchronize SMILES with X and y ---\n",
    "# (Repeat the same filter to ensure X, y, and valid_smiles match)\n",
    "valid_smiles = []\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for index, row in data_csv.iterrows():\n",
    "        mol = Chem.MolFromSmiles(row['SMILES'])\n",
    "        if mol is not None:\n",
    "            valid_smiles.append(row['SMILES'])\n",
    "\n",
    "assert len(valid_smiles) == len(X), \"Synchronization error!\"\n",
    "print(f\"Data synchronized. {len(valid_smiles)} valid molecules ready.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fcb8ae",
   "metadata": {},
   "source": [
    "We split our data into three `setsâ€”Train (80%)`, `Validation (10%)`, and `Test (10%)` to properly evaluate our model's performance. The Train Set is the \"study material\" the model uses to learn patterns. The Validation Set acts as a \"practice exam,\" which we use to tune the model's settings (hyperparameters) and make decisions (like which model is best) without \"cheating.\" Finally, the Test Set is the \"final exam\" that we only use once at the very end. This set provides the final, honest AUROC score and proves our model can generalize to new, unseen data, as outlined in our proposal ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17e70ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Manual Scaffold Split Implementation ---\n",
    "def get_scaffold(smiles):\n",
    "    \"\"\"Obtains the Murcko scaffold of a SMILES.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    try:\n",
    "        scaffold = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "        scaffold_smiles = Chem.MolToSmiles(scaffold, isomericSmiles=False)\n",
    "        # If there is no scaffold (e.g., molecule 'C'), use the original SMILES\n",
    "        return scaffold_smiles if scaffold_smiles else smiles\n",
    "    except:\n",
    "        # Fallback for RDKit versions without GetScaffoldForMol\n",
    "        return smiles\n",
    "\n",
    "# Group indices by scaffold\n",
    "scaffold_groups = defaultdict(list)\n",
    "for i, smiles in enumerate(valid_smiles):\n",
    "    scaffold = get_scaffold(smiles)\n",
    "    scaffold_groups[scaffold].append(i) # Store the index (i)\n",
    "# Now we have a dictionary: {'scaffold_smiles': [list_of_indices]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6cc1786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Split Completed! ---\n",
      "X_train shape: (1175, 2048) | y_train shape: (1175,)\n",
      "X_valid shape: (146, 2048) | y_valid shape: (146,)\n",
      "X_test shape:  (156, 2048)  | y_test shape:  (156,)\n",
      "Total molecules: 1477 (should be 1477)\n",
      "\n",
      "Data saved to 'clintox_ecfp_split.npz'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the *groups* of scaffolds, not the molecules\n",
    "# We want 80% train, 10% valid, 10% test \n",
    "scaffold_list = list(scaffold_groups.keys())\n",
    "train_scaffolds, test_val_scaffolds = train_test_split(scaffold_list, test_size=0.2, random_state=42)\n",
    "valid_scaffolds, test_scaffolds = train_test_split(test_val_scaffolds, test_size=0.5, random_state=42)\n",
    "\n",
    "# Function to reconstruct datasets from indices\n",
    "def get_data_from_scaffolds(scaffold_keys):\n",
    "    indices = [idx for key in scaffold_keys for idx in scaffold_groups[key]]\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "# Reconstruct datasets\n",
    "X_train, y_train = get_data_from_scaffolds(train_scaffolds)\n",
    "X_valid, y_valid = get_data_from_scaffolds(valid_scaffolds)\n",
    "X_test, y_test = get_data_from_scaffolds(test_scaffolds)\n",
    "\n",
    "# --- 4. Split Results ---\n",
    "print(\"\\n---Split Completed! ---\")\n",
    "print(f\"X_train shape: {X_train.shape} | y_train shape: {y_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape} | y_valid shape: {y_valid.shape}\")\n",
    "print(f\"X_test shape:  {X_test.shape}  | y_test shape:  {y_test.shape}\")\n",
    "print(f\"Total molecules: {len(y_train) + len(y_valid) + len(y_test)} (should be {len(X)})\")\n",
    "\n",
    "# --- 5. Save the Split Data ---\n",
    "output_split_filename = 'clintox_ecfp_split.npz'\n",
    "np.savez_compressed(\n",
    "    output_split_filename,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_valid=X_valid, y_valid=y_valid,\n",
    "    X_test=X_test, y_test=y_test\n",
    ")\n",
    "print(f\"\\nData saved to '{output_split_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0badf45",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0840cd",
   "metadata": {},
   "source": [
    "Now we have our data divided into `train`, `test` and `valid`, so we can proceed with the creation of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ab297",
   "metadata": {},
   "source": [
    "### The first model will be a `Random Forest`\n",
    "- Why?  A Random Forest is a non-linear model. It can learn complex, conditional relationships, like \"this substructure is toxic, but only if this other substructure is also present.\" This is much more like real-world biology.\n",
    "- Robustness: RF is an \"ensemble\" model. It builds hundreds of simple \"decision trees\" and lets them vote on the answer. This makes it very robust to noise and less prone to overfitting than a single, deep decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15802b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c213f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-split data from 'clintox_ecfp_split.npz'...\n",
      "Data loaded successfully.\n",
      "\n",
      "Starting GridSearch for Random Forest...\n",
      "Fitting 3 folds for each of 540 candidates, totalling 1620 fits\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading pre-split data from 'clintox_ecfp_split.npz'...\")\n",
    "try:\n",
    "    data = np.load('clintox_ecfp_split.npz')\n",
    "    X_train, y_train = data['X_train'], data['y_train']\n",
    "    X_valid, y_valid = data['X_valid'], data['y_valid']\n",
    "    X_test, y_test = data['X_test'], data['y_test']\n",
    "    \n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'clintox_ecfp_split.npz' not found. Run Step 2 first.\")\n",
    "    raise\n",
    "\n",
    "# --- Define the Model and GridSearch Parameters ---\n",
    "\n",
    "# Initialize the RF Classifier\n",
    "# We MUST include class_weight='balanced' to handle imbalance \n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Define the \"grid\" of hyperparameters to test\n",
    "# This is a small grid to run quickly. You can expand it.\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500, 1000],       \n",
    "    'max_depth': [10, 20, 50, 100, None],          \n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['sqrt', 0.25, 0.5] # 'sqrt' is default, 0.5 means 50% of features\n",
    "}\n",
    "\n",
    "# Initialize GridSearch\n",
    "# We tell it to use 'roc_auc' as its scoring metric \n",
    "# n_jobs=-1 uses all available CPU cores to speed up the search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,  # 3-fold cross-validation on the training data\n",
    "    n_jobs=-1,\n",
    "    verbose=1 # Shows progress\n",
    ")\n",
    "\n",
    "# --- 3. Run the Hyperparameter Search ---\n",
    "print(\"\\nStarting GridSearch for Random Forest...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the grid search on the TRAINING data\n",
    "# GridSearchCV will find the best params using cross-validation\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"...GridSearch complete in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# --- 4. Show Best Parameters and Evaluate on Validation Set ---\n",
    "\n",
    "# This is the best model found by the search\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluate this best model on the VALIDATION set\n",
    "probs_valid_rf = best_rf.predict_proba(X_valid)[:, 1]\n",
    "auc_valid_rf = roc_auc_score(y_valid, probs_valid_rf)\n",
    "print(f\"Best Model Validation AUROC: {auc_valid_rf:.4f}\")\n",
    "\n",
    "# --- 5. Final Evaluation on the TEST Set ---\n",
    "\n",
    "# Now we get the *final*, unbiased score from the test set\n",
    "probs_test_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "auc_test_rf = roc_auc_score(y_test, probs_test_rf)\n",
    "\n",
    "print(f\"\\n--- Final Random Forest Performance ---\")\n",
    "print(f\"Test AUROC: {auc_test_rf:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
